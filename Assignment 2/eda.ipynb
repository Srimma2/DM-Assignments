{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys,os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (15, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  date            time  \\\n",
      "0  2012-10-16 00:00:00  10:28:53-05:00   \n",
      "1  2012-10-16 00:00:00  10:04:30-05:00   \n",
      "2  2012-10-16 00:00:00  09:50:08-05:00   \n",
      "3  2012-10-16 00:00:00  10:00:16-05:00   \n",
      "4  2012-10-16 00:00:00  09:48:07-05:00   \n",
      "\n",
      "                                                text sentiment  \n",
      "0  Kirkpatrick, who wore a baseball cap embroider...         0  \n",
      "1  #<e>obama</e> debates that Cracker Ass Cracker...         1  \n",
      "2  @Hollivan @hereistheanswer  Youre missing the ...         0  \n",
      "3  I was raised as a Democrat  left the party yea...        -1  \n",
      "4  The <e>Obama camp</e> can't afford to lower ex...         0  \n",
      "                  date            time  \\\n",
      "0  2012-10-16 00:00:00  09:38:08-05:00   \n",
      "1  2012-10-16 00:00:00  10:14:18-05:00   \n",
      "2  2012-10-16 00:00:00  09:27:16-05:00   \n",
      "3  2012-10-16 00:00:00  10:11:43-05:00   \n",
      "4  2012-10-16 00:00:00  10:13:17-05:00   \n",
      "\n",
      "                                                text sentiment  \n",
      "0  Insidious!<e>Mitt Romney</e>'s Bain Helped Phi...        -1  \n",
      "1  .@WardBrenda @shortwave8669 @allanbourdius you...        -1  \n",
      "2  <e>Mitt Romney</e> still doesn't <a>believe</a...        -1  \n",
      "3  <e>Romney</e>'s <a>tax plan</a> deserves a 2nd...        -1  \n",
      "4  Hope <e>Romney</e> debate prepped w/ the same ...         1  \n"
     ]
    }
   ],
   "source": [
    "# read the data\n",
    "obama_data = pd.read_excel('training-Obama-Romney-tweets.xlsx',names = ['date','time','text','sentiment'],parse_cols = 4,sheetname = 'Obama')\n",
    "romney_data = pd.read_excel('training-Obama-Romney-tweets.xlsx',names = ['date','time','text','sentiment'],parse_cols = 4,sheetname = 'Romney')\n",
    "\n",
    "def get_data(data):\n",
    "    \"\"\" get and clean the data \"\"\"\n",
    "    data = data.iloc[1:]\n",
    "    data['text'] = data['text'].values.astype('unicode')\n",
    "    data['date'] = data['date'].values.astype('str')\n",
    "    data['time'] = data['time'].values.astype('unicode')\n",
    "    # remove rows with mixed sentiment\n",
    "    data = data[data['sentiment'] < 2]\n",
    "    data.index = range(len(data))\n",
    "    \n",
    "    return data\n",
    "\n",
    "obama_data = get_data(obama_data)\n",
    "romney_data = get_data(romney_data)\n",
    "    \n",
    "print obama_data.head()\n",
    "print romney_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5471 entries, 0 to 5470\n",
      "Data columns (total 4 columns):\n",
      "date         5471 non-null object\n",
      "time         5471 non-null object\n",
      "text         5471 non-null object\n",
      "sentiment    5471 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 213.7+ KB\n",
      "None\n",
      "                       date  time  \\\n",
      "count                  5471  5471   \n",
      "unique                   29  5139   \n",
      "top     2012-10-16 00:00:00   nan   \n",
      "freq                   1292     5   \n",
      "\n",
      "                                                     text  sentiment  \n",
      "count                                                5471       5471  \n",
      "unique                                               5453          3  \n",
      "top     I just knew it...<e>Obama</e> was born in Indo...         -1  \n",
      "freq                                                    3       1922  \n"
     ]
    }
   ],
   "source": [
    "print obama_data.info()\n",
    "print obama_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5648 entries, 0 to 5647\n",
      "Data columns (total 4 columns):\n",
      "date         5648 non-null object\n",
      "time         5648 non-null object\n",
      "text         5648 non-null object\n",
      "sentiment    5648 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 220.6+ KB\n",
      "None\n",
      "                       date            time  \\\n",
      "count                  5648            5648   \n",
      "unique                   20            5342   \n",
      "top     2012-10-16 00:00:00  09:01:31-05:00   \n",
      "freq                   1713               4   \n",
      "\n",
      "                                                     text  sentiment  \n",
      "count                                                5648       5648  \n",
      "unique                                               5637          3  \n",
      "top     Ron Paul Won't Endorse <e>Romney</e>, Says Mor...         -1  \n",
      "freq                                                    2       2893  \n"
     ]
    }
   ],
   "source": [
    "print romney_data.info()\n",
    "print romney_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess(data):\n",
    "    \"\"\" preprocess the data\"\"\"\n",
    "    # remove punctuations\n",
    "    punc = ['\\:','\\;','\\?','\\$','\\.','\\(','\\)','\\#']\n",
    "    cond_1 = re.compile('|'.join(punc))\n",
    "    data['text'] = data['text'].apply(lambda x : re.sub(cond_1,'',x))\n",
    "    # remove tags\n",
    "    tags = ['<a>','</a>','<e>','</e>']\n",
    "    cond_2 = re.compile(\"|\".join(tags))\n",
    "    data['text'] = data['text'].apply(lambda x : re.sub(cond_2,'',x))\n",
    "    # remove users\n",
    "    data['text'] = data['text'].apply(lambda x : re.sub(r'\\@\\w+','',x))\n",
    "    # remove hypertext \n",
    "    data['text'] = data['text'].apply(lambda x : re.sub(r'http://','',x))\n",
    "    # remove digits\n",
    "    data['text'] = data['text'].apply(lambda x : re.sub(r'[0-9]+','',x))\n",
    "    # convert to ascii\n",
    "    data['text'] = data['text'].apply(lambda x: x.encode('utf-8'))\n",
    "    \n",
    "    return data\n",
    "\n",
    "obama_data = preprocess(obama_data)\n",
    "romney_data = preprocess(romney_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_time(data):\n",
    "    \"\"\" processes time \"\"\"\n",
    "\n",
    "    def extract_date(pattern,string):\n",
    "        temp = re.match(pattern,string)\n",
    "        if temp:\n",
    "            return temp.group(1)\n",
    "        else:\n",
    "            return string\n",
    "    # clean date\n",
    "    date_format_1 = re.compile('\\d+/(\\d{2})/\\d+')\n",
    "    date_format_2 = re.compile('\\d+\\-\\d+\\-(\\d{2})')\n",
    "    date_format_3 = re.compile('(\\d{2})\\-[a-zA-Z]+\\-\\d+')\n",
    "    date_format = [date_format_1] + [date_format_2] + [date_format_3]\n",
    "\n",
    "    # remove whitespace\n",
    "    data['date'] = data['date'].apply(lambda x : x.replace(' ',''))\n",
    "\n",
    "    for i in date_format:\n",
    "        data['date'] = data['date'].apply(lambda x: extract_date(i,x))\n",
    "\n",
    "    def converter(first,second):\n",
    "        if first == 'AM':\n",
    "            return second\n",
    "        else:\n",
    "            val = re.findall('(\\d{1,2})',second)[0]\n",
    "            if int(val) > 12:\n",
    "                val = str(int(val) + 12)\n",
    "            return re.sub('\\d{1,2}',val,second,1)\n",
    "\n",
    "    def extract_time(pattern,string):\n",
    "\n",
    "        temp = re.match(pattern,string)\n",
    "        if temp:\n",
    "            first = temp.group(1)\n",
    "            second = temp.group(2)\n",
    "            third = temp.group(3)\n",
    "\n",
    "            if first is None and third is None:\n",
    "                return second\n",
    "\n",
    "            if first == 'AM' or first == 'PM':\n",
    "                return converter(first,second)\n",
    "            else:\n",
    "                return converter(third,second)\n",
    "\n",
    "    # clean time\n",
    "    time_format_1 = re.compile('(AM|PM)?\\s?(\\d{1,2}:\\d{1,2}:\\d{1,2})\\s?(AM|PM)?')\n",
    "\n",
    "    # remove whitespace\n",
    "    data['time'] = data['time'].apply(lambda x : x.replace(' ',''))\n",
    "\n",
    "    data['time'] = data['time'].apply(lambda x : extract_time(time_format_1,x))\n",
    "    data['time'] = pd.to_datetime(data['time'], format='%H:%M:%S')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1    1922\n",
      " 0    1896\n",
      " 1    1653\n",
      "Name: sentiment, dtype: int64\n",
      "-1    2893\n",
      " 0    1680\n",
      " 1    1075\n",
      "Name: sentiment, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Container object of 10 artists>"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3wAAAE8CAYAAACb07NnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEEJPgAAgIL6fwrEXRcph4q0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ec6b5f910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of sentiment\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "obama_heights,obama_bins = np.histogram(obama_data['sentiment'])\n",
    "romney_heights,romney_bins = np.histogram(romney_data['sentiment'],bins = obama_bins)\n",
    "\n",
    "print obama_data['sentiment'].value_counts()\n",
    "print romney_data['sentiment'].value_counts()\n",
    "\n",
    "width = (obama_bins[1] - obama_bins[0])/3\n",
    "\n",
    "ax.bar(obama_bins[:-1],obama_heights,width = width,color = 'blue')\n",
    "ax.bar(romney_bins[:-1]+width,romney_heights,width = width, color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:28:53-05:00</td>\n",
       "      <td>Kirkpatrick, who wore a baseball cap embroider...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:04:30-05:00</td>\n",
       "      <td>obama debates that Cracker Ass Cracker tonight...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:50:08-05:00</td>\n",
       "      <td>Youre missing the point  Im afraid you do n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>10:00:16-05:00</td>\n",
       "      <td>I was raised as a Democrat  left the party yea...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-10-16 00:00:00</td>\n",
       "      <td>09:48:07-05:00</td>\n",
       "      <td>The Obama camp can't afford to lower expectati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date            time  \\\n",
       "0  2012-10-16 00:00:00  10:28:53-05:00   \n",
       "1  2012-10-16 00:00:00  10:04:30-05:00   \n",
       "2  2012-10-16 00:00:00  09:50:08-05:00   \n",
       "3  2012-10-16 00:00:00  10:00:16-05:00   \n",
       "4  2012-10-16 00:00:00  09:48:07-05:00   \n",
       "\n",
       "                                                text sentiment  \n",
       "0  Kirkpatrick, who wore a baseball cap embroider...         0  \n",
       "1  obama debates that Cracker Ass Cracker tonight...         1  \n",
       "2     Youre missing the point  Im afraid you do n...         0  \n",
       "3  I was raised as a Democrat  left the party yea...        -1  \n",
       "4  The Obama camp can't afford to lower expectati...         0  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obama_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IMP - Process Emoticons, better stopwords list, clean hashtags\n",
    "# http://stackoverflow.com/questions/8870261/how-to-split-text-without-spaces-into-list-of-words\n",
    "\n",
    "manual_stopwords_list = ['rt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_list = stopwords.words('english') + manual_stopwords_list\n",
    "\n",
    "# stemming\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "class Tokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5648,) (5648,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def get_X_y(data):\n",
    "    return data['text'],data['sentiment'].astype(int)\n",
    "\n",
    "X,y = get_X_y(romney_data)\n",
    "print X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stopwords_list = []\n",
    "# create a pipeline\n",
    "text_vector = Pipeline([('vect', CountVectorizer(tokenizer = Tokenizer(),stop_words = stopwords_list,ngram_range = (1,2),max_features=10000)),\n",
    "                    ('tfidf',TfidfTransformer())])\n",
    "svd_transform = TruncatedSVD(n_components = 1000,n_iter = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# transform the data\n",
    "X = text_vector.fit_transform(X)\n",
    "X_reduced = svd_transform.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "\n",
    "classifier_scores = dict()\n",
    "\n",
    "def naive_classifier():\n",
    "    return 'Naive_Bayes',MultinomialNB()\n",
    "\n",
    "def svm_classifier():\n",
    "    return 'Linear_SVM',LinearSVC()\n",
    "\n",
    "def sgd_classifier():\n",
    "    return 'SGD',SGDClassifier()\n",
    "\n",
    "classifiers_list = [naive_classifier(),svm_classifier(),sgd_classifier()]\n",
    "\n",
    "for clf_name,clf in classifiers_list:\n",
    "    # dont use reduced matrix for naive bayes\n",
    "    if clf_name != 'Naive_Bayes':\n",
    "            X = X_reduced\n",
    "    classifier_scores[clf_name] = dict()\n",
    "    classifier_scores[clf_name]['classification_pred'] = cross_val_predict(clf,X,y,cv = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier - Naive_Bayes\n",
      "accuracy is 0.561437677054\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.56      0.95      0.70      2893\n",
      "          0       0.51      0.15      0.24      1680\n",
      "          1       0.73      0.16      0.26      1075\n",
      "\n",
      "avg / total       0.58      0.56      0.48      5648\n",
      "\n",
      "\n",
      "\n",
      "Classifier - Linear_SVM\n",
      "accuracy is 0.566395184136\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.63      0.75      0.69      2893\n",
      "          0       0.42      0.35      0.39      1680\n",
      "          1       0.53      0.41      0.46      1075\n",
      "\n",
      "avg / total       0.55      0.57      0.55      5648\n",
      "\n",
      "\n",
      "\n",
      "Classifier - SGD\n",
      "accuracy is 0.556480169972\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.64      0.71      0.67      2893\n",
      "          0       0.43      0.37      0.40      1680\n",
      "          1       0.47      0.45      0.46      1075\n",
      "\n",
      "avg / total       0.55      0.56      0.55      5648\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    " for clf_name,_ in classifiers_list:\n",
    "        print 'Classifier - {}'.format(clf_name)\n",
    "        print 'accuracy is {}'.format(accuracy_score(y,classifier_scores[clf_name]['classification_pred']))\n",
    "        print classification_report(y,classifier_scores[clf_name]['classification_pred'])\n",
    "        print '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "embeddings_dict = {}\n",
    "f = open(os.path.join('glove.twitter.27B', 'glove.twitter.27B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_dict[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,y = get_X_y(obama_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingVectorizer(CountVectorizer):\n",
    "    def __init__(self,**kwargs):\n",
    "        self.embeddings_dict = kwargs.pop('word2vec')\n",
    "        # if a text is empty we should return a vector of zeros\n",
    "        # with the same dimensionality as all the other vectors\n",
    "        self.dim = 100\n",
    "        super(EmbeddingVectorizer,self).__init__(**kwargs)\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.embeddings_dict[w] for w in words if w in self.embeddings_dict]\n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "    def fit_transform(self,X,y):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert to word vectors\n",
    "text_vector = Pipeline([('vect', EmbeddingVectorizer(word2vec = embeddings_dict,tokenizer = Tokenizer(),stop_words = stopwords_list)),\n",
    "                ('classifier',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545231788521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(10)\n",
    "\n",
    "scores = []\n",
    "for train,test in k_fold.split(X,y):\n",
    "    text_vector.fit_transform(X[train],y[train])\n",
    "    pred_val = text_vector.predict(X[test])\n",
    "    scores.append(np.mean(pred_val != y[test]))\n",
    "\n",
    "print sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
